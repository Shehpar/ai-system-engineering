# AI Infrastructure Anomaly Detection System

[![Tests](https://github.com/Shehpar/ai-system-engineering/actions/workflows/tests.yml/badge.svg)](https://github.com/Shehpar/ai-system-engineering/actions)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-29.1.3+-blue.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

**Course**: AI Systems Engineering (Fall 2025)  
**Student Project**: Innovation-driven (INN)  
**Status**: âœ… Production Ready - All Course Requirements Met

---

## ðŸŽ¯ Overview

A production-grade AI system for **real-time infrastructure anomaly detection** using Isolation Forest machine learning with comprehensive MLOps infrastructure. Detects anomalies in system metrics (CPU, Memory, Network) with <10ms latency.

### Key Features

- **ðŸ¤– Advanced ML Pipeline**: Offline training, grid search optimization, SHAP explainability
- **ðŸ“Š Real-time Monitoring**: Live anomaly detection with 6.94ms latency
- **ðŸ“ˆ Auto-Provisioned Dashboards**: Grafana + InfluxDB time-series storage
- **ðŸ”¬ Experiment Tracking**: MLflow integration for full reproducibility
- **ðŸ³ Container-Level Monitoring**: Per-container CPU, Memory, Network, Status metrics
- **ðŸ”¥ HTTP Stress Testing**: DoS simulation with configurable load (200 RPS default)
- **ðŸŽ¯ Real Data Collection**: Extracts actual metrics from InfluxDB (24h window)
- **âš¡ One-Command Deployment**: Automated setup script (3-5 minutes)
- **ðŸ§ª Automated Testing**: Comprehensive validation with stress simulation
- **âœ… Quality Assurance**: 5 unit tests (100% passing), structured logging, health checks
- **ðŸ“š Professional Documentation**: 70+ pages covering all aspects
- **ðŸš€ CI/CD Ready**: Complete containerized deployment with GitHub Actions

---

## ðŸš€ Quick Start (1 Command - 3 Minutes)

### Automated Setup (Recommended)

```powershell
# Complete setup from scratch - One command!
.\setup_and_run.ps1 -CleanInstall

# Wait 3-5 minutes for automated:
# âœ… Service startup (InfluxDB, Grafana, MLflow)
# âœ… Database creation
# âœ… Data collection/generation
# âœ… Model training
# âœ… Monitoring & AI detection startup
```

### Access Dashboards
- **Grafana** (Visualization): http://localhost:3000 (admin/admin)
- **MLflow** (Experiments): http://localhost:5000
- **InfluxDB** (Database): http://localhost:8086
- **Flask App**: http://localhost:5005

### Testing & Validation

```powershell
# Run comprehensive tests with stress simulation
.\test_and_validate.ps1

# Custom test (2 minutes, 300 RPS)
.\test_and_validate.ps1 -Duration 120 -RequestsPerSecond 300
```

---

## ðŸ“– Manual Setup (Alternative)

If you prefer step-by-step manual control:

---

## ðŸ“Š Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   MONITORING LAYER                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Grafana (Port 3000) â† Auto-Provisioned Dashboard      â”‚
â”‚  MLflow (Port 5000) â† Experiment Tracking              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             INFERENCE & ANALYTICS LAYER                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Python ML Pipeline:                                     â”‚
â”‚  â”œâ”€ detect_anomaly.py: Real-time predictions           â”‚
â”‚  â”œâ”€ train_model.py: Offline training (grid search)     â”‚
â”‚  â”œâ”€ validate_data.py: Data quality checks              â”‚
â”‚  â””â”€ evaluate_model.py: Robustness testing              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             DATA STORAGE & TRACKING                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  InfluxDB (Port 8086) â† Time-Series Metrics            â”‚
â”‚  MLflow â† Model Artifacts & Experiments                 â”‚
â”‚  CSV Files â† Raw & Processed Data                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             DATA COLLECTION LAYER                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Telegraf â† Infrastructure Metrics                      â”‚
â”‚  Flask App â† Simulated System Metrics                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“¦ System Requirements

- **Docker**: 29.1.3+ ([Get Docker](https://docs.docker.com/get-docker/))
- **Docker Compose**: 2.0+ (included with Docker Desktop)
- **RAM**: 4GB minimum (8GB recommended)
- **Disk**: 5GB for images and data
- **Python**: 3.11+ (for local development; CI uses 3.11 and 3.12)

---

## ðŸ“‹ Installation

### Docker Deployment (Recommended)

```bash
# Clone and enter directory
git clone https://github.com/Shehpar/ai-system-engineering.git
cd ai-infrastructure-anomaly-detection

# Start all services
docker-compose -f docker/docker-compose.yml up -d

# Verify healthy status
docker-compose -f docker/docker-compose.yml ps

# View logs
docker-compose -f docker/docker-compose.yml logs -f ai_app

# Stop services
docker-compose -f docker/docker-compose.yml down
```

### Local Python Setup

```bash
# Requires Python 3.11+ (CI runs on 3.11 and 3.12)
# Install dependencies
pip install -r requirements.txt

# Train model
python src/train_model.py

# Validate data
python src/validate_data.py

# Evaluate robustness
python src/evaluate_model.py

# Run tests
pytest tests/ -v
```

---

## ðŸ§ª Testing

### Run Unit Tests
```bash
# Via Docker
docker-compose -f docker/docker-compose.yml exec -T ai_app pytest tests/ -v

# Locally
pytest tests/ -v
```

**Test Results**:
- test_split_data_shapes: âœ… PASSED
- test_validate_schema_pass: âœ… PASSED
- test_validate_schema_fail: âœ… PASSED
- test_validate_ranges_fail_when_outside_bounds: âœ… PASSED
- test_validate_live_data: âœ… PASSED

**Total**: 5/5 tests passing (100%)

---

## ðŸ“Š Model Performance (Jan 28, 2026)

### Baseline Metrics
| Metric | Value | Target | Status |
|--------|-------|--------|--------|
| **Precision** | 100.0% | â‰¥90% | âœ… EXCEEDS |
| **Recall** | 72.73% | â‰¥90% | âš ï¸ ACCEPTABLE |
| **F1-Score** | 84.21% | â‰¥85% | âš ï¸ NEAR |
| **ROC-AUC** | 100.0% | â‰¥95% | âœ… EXCEEDS |
| **Latency** | 6.94ms | <5s | âœ… EXCEEDS |

### Robustness Results
- âœ… **Noise**: Stable under Ïƒ=0.01-0.1 Gaussian noise
- âœ… **Missing Data**: Handles feature imputation gracefully
- âœ… **Outliers**: 100% detection rate for 10x magnitude anomalies
- âœ… **SHAP**: Explains per-feature contributions to anomalies

See [docs/MODEL_CARD.md](docs/MODEL_CARD.md) for detailed results.

---

## ðŸ“ Project Structure

```
ai-infrastructure-anomaly-detection/
â”œâ”€â”€ src/                              # Python ML pipeline
â”‚   â”œâ”€â”€ train_model.py               # Offline training with grid search
â”‚   â”œâ”€â”€ validate_data.py             # Data quality validation (6 checks)
â”‚   â”œâ”€â”€ evaluate_model.py            # Robustness testing (4 scenarios)
â”‚   â””â”€â”€ detect_anomaly.py            # Real-time inference with SHAP explainability
â”œâ”€â”€ tests/                           # Unit tests (5 test cases)
â”‚   â”œâ”€â”€ conftest.py                  # pytest configuration
â”‚   â”œâ”€â”€ test_train_model.py
â”‚   â””â”€â”€ test_validate_data.py
â”œâ”€â”€ docker/                          # Containerization
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml           # 4 services: ai_app, influxdb, grafana, mlflow
â”œâ”€â”€ grafana/                         # Auto-provisioning
â”‚   â””â”€â”€ provisioning/
â”‚       â”œâ”€â”€ datasources/influxdb.yml
â”‚       â””â”€â”€ dashboards/
â”‚           â”œâ”€â”€ dashboard.yml
â”‚           â””â”€â”€ grafana_dashboard.json
â”œâ”€â”€ mlflow/                          # Experiment tracking
â”‚   â”œâ”€â”€ mlflow.db                    # SQLite backend
â”‚   â””â”€â”€ artifacts/                   # Model artifacts
â”œâ”€â”€ data/                            # Data storage
â”‚   â”œâ”€â”€ raw/system_metrics.csv
â”‚   â””â”€â”€ processed/system_metrics_processed.csv
â”œâ”€â”€ models/                          # Trained models with versioning
â”‚   â””â”€â”€ anomaly_model_v20260128_145609.pkl
â”œâ”€â”€ results/                         # Training/evaluation reports
â”‚   â”œâ”€â”€ training_metrics_*.json
â”‚   â”œâ”€â”€ validation_report_*.json
â”‚   â””â”€â”€ evaluation_report_*.json
â”œâ”€â”€ docs/                            # Comprehensive documentation
â”‚   â”œâ”€â”€ REQUIREMENTS.md              # Problem statement & KPIs
â”‚   â”œâ”€â”€ ARCHITECTURE.md              # System design & data flow
â”‚   â”œâ”€â”€ MODEL_CARD.md                # Algorithm & robustness
â”‚   â””â”€â”€ DEPLOYMENT.md                # Operations guide
â”œâ”€â”€ .github/workflows/tests.yml      # CI/CD pipeline
â”œâ”€â”€ requirements.txt                 # Python dependencies
â””â”€â”€ README.md                        # This file
```

### Related Folders in the Workspace

- [../datacenter](../datacenter) â€” Flask-based metric generator + Telegraf config used for realistic data ingestion.
    - docker-compose.yml, telegraf.conf
    - flask_app/ (app.py, stress_test.py, Dockerfile, entrypoint.sh)
    - flask_logs/ (runtime logs)
- [../stress-test-docker](../stress-test-docker) â€” Standalone HTTP load generator for stress testing.
    - docker-compose.yml, Dockerfile, entrypoint.sh
    - http_load_generator.py, stress.py, requirements.txt

---

## ðŸ”§ Configuration

### Environment Variables

```bash
# Log level (INFO, DEBUG, WARNING, ERROR)
export LOG_LEVEL=INFO

# MLflow tracking URI
export MLFLOW_TRACKING_URI=http://mlflow:5000

# InfluxDB connection
export INFLUXDB_HOST=influxdb
export INFLUXDB_PORT=8086
export INFLUXDB_DATABASE=system_metrics
```

### Docker Customization

Edit `docker/docker-compose.yml` to adjust:
- Port numbers (3000, 5000, 8086)
- Resource limits (CPU, RAM)
- Healthcheck intervals
- Environment variables

---

## ðŸ“Š Dashboard Access

### Grafana (http://localhost:3000)
- **Login**: admin / admin
- **Dashboard**: "AI Anomaly Detection" (auto-loads)
- **Features**: Real-time anomalies, trends, alerts, custom panels

### MLflow (http://localhost:5000)
- **Experiments**: anomaly_detection_training
- **Metrics**: Precision, Recall, F1, ROC-AUC
- **Artifacts**: Models, scalers, reports
- **Comparison**: A/B test runs

---

## ðŸ” Monitoring & Logging

### View Logs

```bash
# All services with timestamps
docker-compose -f docker/docker-compose.yml logs -f --timestamps

# Specific service
docker-compose -f docker/docker-compose.yml logs -f ai_app

# Real-time with filtering
docker-compose -f docker/docker-compose.yml logs -f ai_app | grep "ERROR"
```

### Structured Logging

All scripts use Python `logging` module:

```bash
# View with different verbosity
export LOG_LEVEL=DEBUG  # Verbose
export LOG_LEVEL=INFO   # Normal
export LOG_LEVEL=ERROR  # Production
```

### Health Checks

```bash
# View service health status
docker-compose -f docker/docker-compose.yml ps

# Detailed health info
docker inspect docker-ai_app-1 | grep -A 5 Health
```

---

## ðŸš€ Common Tasks

### Automated Workflows

```powershell
# Complete setup from scratch
.\setup_and_run.ps1 -CleanInstall

# Run validation tests
.\test_and_validate.ps1

# Custom stress test (5 min, 500 RPS)
.\test_and_validate.ps1 -Duration 300 -RequestsPerSecond 500
```

### Manual Operations

```bash
# Train a new model
docker-compose -f docker/docker-compose.yml exec -T ai_app python src/train_model.py

# Collect real data from InfluxDB
docker-compose -f docker/docker-compose.yml exec -T ai_app python src/collect_real_data.py

# Validate data quality
docker-compose -f docker/docker-compose.yml exec -T ai_app python src/validate_data.py

# Test model robustness
docker-compose -f docker/docker-compose.yml exec -T ai_app python src/evaluate_model.py

# Run unit tests
docker-compose -f docker/docker-compose.yml exec -T ai_app pytest tests/ -v
```

---

## ðŸ“š Documentation

Full documentation in `/docs`:

| Document | Content |
|----------|---------|
| [AUTOMATION_GUIDE.md](docs/AUTOMATION_GUIDE.md) | Automated setup & testing scripts (NEW) |
- [TIER_1_SUMMARY.md](../TIER_1_SUMMARY.md) - MLOps core (8 components)
- [TIER_2_SUMMARY.md](../TIER_2_SUMMARY.md) - QA & operations (6 components)
- [IMPLEMENTATION_ROADMAP.md](../IMPLEMENTATION_ROADMAP.md) - Course alignment

---

## ðŸ”„ MLOps Pipeline

### Training Workflow
1. Load historical metrics (CSV)
2. Validate data quality (6 checks)
3. Split 70/15/15 (train/val/test)
4. Grid search hyperparameters
5. Train Isolation Forest
6. Evaluate metrics
7. Version model with timestamp
8. Log to MLflow

### Inference Workflow
1. Query live metrics from InfluxDB
2. Apply fitted scaler
3. Get predictions + anomaly scores
4. Write results to InfluxDB
5. View SHAP feature contributions
6. Trigger retraining if needed

---

## ðŸ› Troubleshooting

### Services Not Starting
```bash
# Check Docker daemon
docker --version

# View detailed logs
docker-compose -f docker/docker-compose.yml logs

# Rebuild fresh
docker-compose -f docker/docker-compose.yml down -v
docker-compose -f docker/docker-compose.yml up -d --build
```

### Grafana Dashboard Not Loading
```bash
# Wait 30 seconds for startup
# Refresh browser
# Check provisioning:
docker exec docker-grafana-1 ls /etc/grafana/provisioning/dashboards/
```

### Tests Failing
```bash
# Verbose output
docker-compose -f docker/docker-compose.yml exec -T ai_app pytest tests/ -vv

# Verify data exists
docker-compose -f docker/docker-compose.yml exec -T ai_app ls -la data/processed/
```

---

## ðŸŽ“ Course Information

**Course**: AI Systems Engineering  
**Semester**: Fall 2025  
**Project Type**: Innovation-driven (INN)  

**Requirements Coverage**:
- âœ… Part I: Design (REQUIREMENTS.md, ARCHITECTURE.md)
- âœ… Part II: Development (train_model.py, validate_data.py)
- âœ… Part III: Verification (evaluate_model.py, tests/)
- âœ… Part IV: Operations (docker-compose.yml, grafana/, mlflow/)

---

## ðŸ“Š Project Statistics

- **Python Code**: 1000+ lines
- **Tests**: 5 unit tests (100% passing)
- **Documentation**: 65+ pages
- **Docker Services**: 4 (with health checks)
- **CI/CD**: GitHub Actions workflow
- **Git Commits**: 15+ with detailed history

---

## ðŸ” Security & License

- **License**: MIT
- **Security**: Dependency scanning via GitHub Actions
- **Code Quality**: Linting and vulnerability checks

---

## ðŸš€ Next Steps (Tier 3 - Optional)

Advanced MLOps features for production scale:
- [ ] MLflow Model Registry
- [ ] Blue-green deployment
- [ ] SHAP explainability
- [ ] Additional SHAP dashboards
- [ ] Kubernetes deployment

See [../IMPLEMENTATION_ROADMAP.md](../IMPLEMENTATION_ROADMAP.md) for details.

---

**Repository**: https://github.com/Shehpar/ai-system-engineering  
**Last Updated**: January 28, 2026  
**Status**: âœ… Production Ready
